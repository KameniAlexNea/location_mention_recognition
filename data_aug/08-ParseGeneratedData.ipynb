{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob(\"augment/*\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "loaded_files: list[str] = []\n",
    "to_check = []\n",
    "\n",
    "def load_and_check(path: str):\n",
    "\tllm_output = open(path).read()\n",
    "\n",
    "\t# location_labels = []\n",
    "\n",
    "\tpattern = r'<ner>(.*?)</ner>'\n",
    "\tmatches: list[str] = re.findall(pattern, llm_output, re.DOTALL)\n",
    "\n",
    "\tif len(matches) < 100:\n",
    "\t\tpatch = []\n",
    "\t\n",
    "\t\tfmatches = [i for i in matches if \"<ner>\" in i]\n",
    "\t\tpatch = [i for i in matches if \"<ner>\" not in i]\n",
    "\n",
    "\t\t# loaded_files.extend(nmatches)\n",
    "\t\tpatch.extend(j.strip() for i in fmatches for j in i.split(\"<ner>\"))\n",
    "\t\tif len(patch) == 100 or not fmatches:\n",
    "\t\t\tloaded_files.extend(patch)\n",
    "\t\telse:\n",
    "\t\t\tprint(path)\n",
    "\t\t\tto_check.append(path)\n",
    "\t\t\tprint(len(fmatches))\n",
    "\t\t\tfor i in fmatches:\n",
    "\t\t\t\tprint(i)\n",
    "\t\t\t\tprint()\n",
    "\t\t\tprint(\"\\n\")\n",
    "\telse:\n",
    "\t\tloaded_files.extend(matches)\n",
    "\t# for i in fmatches:\n",
    "\t# \tprint(i)\n",
    "\t# print(len(matches))\n",
    "# for match in matches:\n",
    "# \t# Split the content into lines and remove leading/trailing whitespace and dashes\n",
    "# \tpass\n",
    "\n",
    "for file in files:\n",
    "\tload_and_check(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16782"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'augment/4e36bcb0-3a6e-4765-818a-b1d113fa6613'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The O\n",
      "American O\n",
      "RedCross O\n",
      "is O\n",
      "providing O\n",
      "relief O\n",
      "efforts O\n",
      "to O\n",
      "the O\n",
      "people O\n",
      "of O\n",
      "Puerto B-LOC\n",
      "Rico I-LOC\n",
      "after O\n",
      "Hurricane O\n",
      "Fiona O\n",
      "made O\n",
      "landfall O\n",
      ". O\n",
      "Our O\n",
      "team O\n",
      "in O\n",
      "New B-LOC\n",
      "York I-LOC\n",
      "is O\n",
      "also O\n",
      "collecting O\n",
      "donations O\n",
      "for O\n",
      "the B-LOC\n",
      "victims O\n",
      "of O\n",
      "the O\n",
      "disaster O\n"
     ]
    }
   ],
   "source": [
    "print(loaded_files[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_entities = []\n",
    "tags = [\"O\", \"B-LOC\", \"I-LOC\"]\n",
    "ponct = \".!,#\"\n",
    "\n",
    "def check_sentence(raw: tuple[str, str]):\n",
    "\treturn ((len(raw) == 2) and (raw[1] in tags)) # or ((len(raw) == 1) and (raw[0] in ponct))\n",
    "\n",
    "for sentence in loaded_files: # example\n",
    "\texample = []\n",
    "\tword_ner_list = sentence.strip().split(\"\\n\") # list of (word, ner)\n",
    "\trow_splts = [word_ner.split() for word_ner in word_ner_list]\n",
    "\t# len(i) == 2 and i[1] in tags\n",
    "\tif all(check_sentence(i) for i in row_splts):\n",
    "\t\tperfect_entities.append(sentence.strip().replace(\"the B-LOC\", \"the O\"))\n",
    "\t# for word_ner in word_ner_list:\n",
    "\t# \tif not word_ner:\n",
    "\t# \t\tcontinue\n",
    "\t# \trow_splts = word_ner.split()\n",
    "\n",
    "\t\t# row_splts = [\n",
    "\t\t# \trow_splts[i: i + 2] for i in range(0, len(row_splts), 2)\n",
    "\t\t# ]\n",
    "\t\t# for i, row_splt in enumerate(row_splts):\n",
    "\t\t# \tflag = False\n",
    "\t\t# \tif len(row_splt) == 2:\n",
    "\t\t# \t\tlab = row_splt[1]\n",
    "\t\t# \t\tif lab[:4] in [\"O\", \"B-LOC\", \"I-LOC\"]:\n",
    "\t\t# \t\t\tif len(lab) <= 4:\n",
    "\t\t# \t\t\t\texample.append(row_splt)\n",
    "\t\t\t\t\t\n",
    "\t\t# \t\t\tflag = True\n",
    "\t\t\t\t\n",
    "\t\t# print(row_splts)\n",
    "\t# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6030"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(perfect_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emergency O\n",
      "workers O\n",
      "are O\n",
      "providing O\n",
      "aid O\n",
      "to O\n",
      "thousands O\n",
      "of O\n",
      "people O\n",
      "affected O\n",
      "by O\n",
      "a O\n",
      "devastating O\n",
      "hurricane O\n",
      "that O\n",
      "hit O\n",
      "the O\n",
      "Caribbean B-LOC\n",
      ", I-LOC\n",
      "specifically O\n",
      "Puerto O\n",
      "Rico's I-LOC\n",
      "western I-LOC\n",
      "coastline I-LOC\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "print(random.choice(perfect_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"\\n\\n\".join(perfect_entities)\n",
    "with open(\"data/ExtratTrain.txt\", \"w\") as f:\n",
    "    f.write(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
