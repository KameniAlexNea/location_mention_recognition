{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"mscft_ner\"\n",
    "\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-10 13:33:29,566 SequenceTagger predicts: Dictionary with 5 tags: O, B-LOC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "PATH = \"flair_finetuning/debertav3/best-model.pt\" # \"urchade/gliner_small-v2.1\"\n",
    "\n",
    "model = SequenceTagger.load(PATH,).cuda() #  load_tokenizer=True\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1645\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>And we know nothing about the damage caused by...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>. @ SBSbroadcasting sends 100 , 000 pounds of ...</td>\n",
       "      <td>Puerto Rico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td># CycloneIdai update : we aim to reach + 500k ...</td>\n",
       "      <td>Malawi Mozambique Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Rush lacrosse club raising $ 50K for Fort McMu...</td>\n",
       "      <td>Fort McMurray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Any donation to @ topos helps the victims of t...</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "616   And we know nothing about the damage caused by...   \n",
       "1480  . @ SBSbroadcasting sends 100 , 000 pounds of ...   \n",
       "29    # CycloneIdai update : we aim to reach + 500k ...   \n",
       "103   Rush lacrosse club raising $ 50K for Fort McMu...   \n",
       "34    Any donation to @ topos helps the victims of t...   \n",
       "\n",
       "                        location  \n",
       "616                               \n",
       "1480                 Puerto Rico  \n",
       "29    Malawi Mozambique Zimbabwe  \n",
       "103                Fort McMurray  \n",
       "34                        Mexico  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "raw_test = json.load(open(\"data/accepted_data/TestCleaned.json\"))\n",
    "texts = [\n",
    "    \" \".join(i[\"tokenized_text\"]) for i in raw_test\n",
    "]\n",
    "\n",
    "def get_expected(raw):\n",
    "    entities = [\n",
    "        \" \".join(raw[\"tokenized_text\"][i[0]: i[1] + 1]) for i in raw[\"ner\"]\n",
    "    ]\n",
    "    return \" \".join(sorted(entities))\n",
    "ners = [\n",
    "    get_expected(i) for i in raw_test\n",
    "]\n",
    "test_data = pd.DataFrame(zip(texts, ners), columns=[\"text\", \"location\"])\n",
    "print(len(test_data))\n",
    "\n",
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "texts = [Sentence(i) for i in test_data[\"text\"].tolist()]\n",
    "\n",
    "model.predict(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch inference: 100%|██████████| 52/52 [00:23<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "model.predict(texts, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence[52]: \"Kerala Govt has opened a new website to co - ordinate the flood relief efforts . Kindly visit to 1 . Request for help 2 . District Needs 3 . To Contribute 4 . Register as a Volunteer 5 . Contact different camps 6 . To know d registered requests # KeralaFloods2018\" → [\"Kerala\"/LOC]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "for entity in texts[10].get_spans(\"ner\"):\n",
    "    if entity.tag == \"LOC\":\n",
    "        pred.append(\n",
    "            {\n",
    "                \"entity\": entity.tag,\n",
    "                \"word\": entity.text,\n",
    "                \"start\": entity.start_position,\n",
    "                \"end\": entity.end_position,\n",
    "                \"probs\": entity.score\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LOC',\n",
       "  'word': 'Kerala',\n",
       "  'start': 0,\n",
       "  'end': 6,\n",
       "  'probs': 0.9961767196655273}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditions = []\n",
    "for text in texts:\n",
    "\tpred = []\n",
    "\n",
    "\tfor entity in text.get_spans(\"ner\"):\n",
    "\t\tif entity.tag == \"LOC\":\n",
    "\t\t\tpred.append(\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"entity\": entity.tag,\n",
    "\t\t\t\t\t\"word\": entity.text,\n",
    "\t\t\t\t\t\"start\": entity.start_position,\n",
    "\t\t\t\t\t\"end\": entity.end_position,\n",
    "\t\t\t\t\t\"probs\": entity.score\n",
    "\t\t\t\t}\n",
    "\t\t\t)\n",
    "\n",
    "\tpreditions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LOC',\n",
       "  'word': 'Clarence River',\n",
       "  'start': 37,\n",
       "  'end': 51,\n",
       "  'probs': 0.9953771531581879}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preditions[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ellicott City Maryland Maryland'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raws = [\n",
    "    \" \".join(sorted(i[\"word\"] for i in pred)) or \"@\" for pred in preditions\n",
    "]\n",
    "\n",
    "raws[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_data[\"location\"] == \"\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ellicott City Maryland Maryland'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.loc[test_data[\"location\"] == \"\", \"location\"] = \"@\"\n",
    "\n",
    "expected = test_data[\"location\"].tolist()\n",
    "\n",
    "expected[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16406547392462886"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "wer = load(\"wer\")\n",
    "\n",
    "wer.compute(predictions=raws, references=expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1815.000000\n",
       "mean        0.975094\n",
       "std         0.073932\n",
       "min         0.391826\n",
       "25%         0.991646\n",
       "50%         0.997539\n",
       "75%         0.998732\n",
       "max         0.999396\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = [\n",
    "    i[\"probs\"] for pred in preditions for i in pred\n",
    "]\n",
    "\n",
    "pd.Series(probs).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18880852683669586 0.0\n",
      "0.1884278644842025 0.4081632653061224\n",
      "0.18804720213170917 0.44897959183673464\n",
      "0.18652455272173582 0.5306122448979591\n",
      "0.18614389036924248 0.5510204081632653\n",
      "0.18500190331176247 0.5714285714285714\n",
      "0.18462124095926913 0.5918367346938775\n",
      "0.18424057860677578 0.6122448979591836\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def drop_duplicate(places):\n",
    "    return sorted(list(set(places)))\n",
    "\n",
    "def compute_score(thr: float = .5):\n",
    "    raws = [\n",
    "\t\t\" \".join(drop_duplicate(i[\"word\"] for i in pred if i[\"probs\"] >= thr)) or \"@\" for pred in preditions\n",
    "\t]\n",
    "    return wer.compute(predictions=raws, references=expected)\n",
    "\n",
    "best_score, best_thr = 1000, 0\n",
    "for thr in np.linspace(0.0, 1, 50):\n",
    "    score = compute_score(thr)\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_thr = thr\n",
    "        print(score, thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0.1727126805778491 0.1\n",
    "* 0.1723916532905297 0.4724137931034482\n",
    "* 0.17207062600321027 0.5344827586206896\n",
    "* 0.17142857142857143 0.5655172413793104\n",
    "* 0.1707865168539326 0.596551724137931\n",
    "* 0.17046548956661317 0.6586206896551724\n",
    "* 0.1682182985553772 0.689655172413793\n",
    "* 0.1666131621187801 0.7206896551724138\n",
    "* 0.16565008025682182 0.8448275862068965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16406547392462886 0.0\n",
      "0.16368481157213552 0.4081632653061224\n",
      "0.16330414921964218 0.44897959183673464\n",
      "0.16178149980966883 0.5306122448979591\n",
      "0.16102017510468214 0.5510204081632653\n",
      "0.1594975256947088 0.5714285714285714\n",
      "0.15911686334221545 0.5918367346938775\n",
      "0.1583555386372288 0.6122448979591836\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def drop_duplicate(places):\n",
    "    return sorted(places)\n",
    "\n",
    "def compute_score(thr: float = .5):\n",
    "    raws = [\n",
    "\t\t\" \".join(drop_duplicate(i[\"word\"] for i in pred if i[\"probs\"] >= thr)) or \"@\" for pred in preditions\n",
    "\t]\n",
    "    return wer.compute(predictions=raws, references=expected)\n",
    "\n",
    "best_score, best_thr = 1000, 0\n",
    "for thr in np.linspace(0.0, 1, 50):\n",
    "    score = compute_score(thr)\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_thr = thr\n",
    "        print(score, thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
